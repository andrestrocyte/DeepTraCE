{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d09b7b10",
   "metadata": {},
   "source": [
    "## DeepTraCE analysis pipeline\n",
    "\n",
    "This notebook exemplifies how to process a brain with deeptrace for python.\n",
    "\n",
    "\n",
    "Data can be loaded using the ``BrainStack`` class. Brain rotation, segmentation and alignment can be ran using the ``.deeptrace_analysis`` method in the ``BrainStack`` class.\n",
    "\n",
    "### Analysis steps:\n",
    "\n",
    "1) Select the stack (we tipically use 2 channels, 488 and 640 - the brains are registered to 488). Load the brains to the ``BrainStack`` - as in cell 1.\n",
    "2) Correct the rotation angles of the brain. When you run the first cell, the 488 stack will be downsampled and opened on a GUI. **Use this gui to select 2 locations of the frame that are in the same plane.** To do this:\n",
    "    - find the blood vessels in medial sections and place the mouse over a vessel. Press the ``z`` key to mark the first coordinates/plane.\n",
    "    - Use the slider or the arrows to find a **more medial** plane that has the same vessel and place the mouse over the same vessel (x and y coords of the vessel are different from the first point). Press the ``shift z`` key combination to record the second point.\n",
    "    \n",
    "3) Once the points have been selected, run the second cell. That will run all segmentation models; register the stacks to the average. \n",
    "4) Run the third cell for combining the models and preparing the resuts.\n",
    "\n",
    "All results are saved to a folder named ``deeptrace_analysis`` one level up from the raw stacks.\n",
    "\n",
    "---\n",
    "\n",
    "**Important:**\n",
    "The first time deeptrace is imported, it will create a folder in the user folder called ``DeepTraCE`` (i.e. in ``C:\\Users\\USERNAME\\DeepTraCE`` on windows, ``\\home\\USERNAME\\DeepTraCE`` on linux or ``\\Users\\USERNAME\\DeepTraCE`` on mac).\n",
    "You can retrieve the path running ``import deeptrace;print(deeptrace.utils.deeptrace_path)``\n",
    "\n",
    "The ``DeepTraCE`` folder contains:\n",
    "- **DeepTraCE_preferences.json** - A file with the paths and preferences\n",
    "- **models** - a folder with all the models to be ran in hdf5 format\n",
    "- **registration** - a folder with the files required to register the brainbrains to the reference, this will include:\n",
    "   - *average_template_lsfm_10_crop_flip.tif*   - reference brain\n",
    "   - *annotation_10_lsfm_collapse_crop_flip_newf.nrrd* - annotated atlas\n",
    "   - *aba_ontology.csv* - table with the region names\n",
    "   - *model_selection.csv* - table to select which model gets used for each area\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2ad307",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TRAILMAP network and model.\n",
      "Using model weight denardo_model3.hdf5\n",
      "Created /home/joao/deeptrace_data/deeptrace_analysis/210723_NAc326F_488_s3_0_8x_13-31-25/denardo_model3_seg_210723_NAc326F_640_s3_0_8x_11-50-51\n"
     ]
    }
   ],
   "source": [
    "# This will open the figure for you to select the angles\n",
    "%matplotlib qt  # This line is needed to interactively select the angles\n",
    "\n",
    "from deeptrace import *\n",
    "from deeptrace.plotting import *\n",
    "import time\n",
    "tstart = time.time()\n",
    "# get the stack and downsample it\n",
    "stack = BrainStack(['/home/joao/deeptrace_data/210723_NAc326F_488_s3_0_8x_13-31-25/',\n",
    "                  '/home/joao/deeptrace_data/210723_NAc326F_640_s3_0_8x_11-50-51/'])\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "pbar = tqdm()\n",
    "# Open the angle selection GUI\n",
    "res = stack.deeptrace_analysis(angles = None,\n",
    "                               trailmap_models = [f for f in np.sort(trailmap_list_models())[:3]],\n",
    "                               pbar = pbar)\n",
    "pbar.close()\n",
    "print(time.time() - tstart)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921f024c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will run TRAILMAP (it takes a while and uses the GPU)\n",
    "# the angles are taken from the previous cell\n",
    "# select the models in the list\n",
    "pbar = tqdm()\n",
    "res = stack.deeptrace_analysis(angles = [float(f) for f in res['angles']],\n",
    "                               trailmap_models = trailmap_list_models()[:3], # uses the first 3 models\n",
    "                               pbar = pbar)\n",
    "pbar.close()\n",
    "print(time.time() - tstart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd97a492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This does the counting and combines the models\n",
    "# load results\n",
    "params,autof,models = load_deeptrace_models(res['analysis_folder'])\n",
    "print(\"Combining models\") \n",
    "combined,model_selection = combine_models(models, default_model=2)  # select the default model here\n",
    "print(\"Refining model using connected components analysis\")\n",
    "refined_model = refine_connected_components(combined)\n",
    "print(\"Performing quantification.\")\n",
    "res = count_labeling_density(refined_model, model_selection)\n",
    "res.to_csv(pjoin(res['analysis_folder'],'area_quantification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540712ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this plots the quantifications\n",
    "# %matplotlib inline # ti see the plots in the browser; does not work with interact_stack_overlay_areas\n",
    "\n",
    "plt.figure(figsize = [20,5])\n",
    "plt.bar(np.arange(len(res)),np.array(res.density),color = res.color)\n",
    "plt.xticks(np.arange(len(res)),res.acronym,rotation = 90,fontsize = 7);\n",
    "plt.xlim([-1,len(res)])\n",
    "plt.ylabel('Density normalized by area volume',fontsize = 14)\n",
    "\n",
    "plt.figure(figsize = [20,5])\n",
    "plt.bar(np.arange(len(res)),res.count_pixels/np.sum(res.count_pixels),color = res.color)\n",
    "plt.xticks(np.arange(len(res)),res.acronym,rotation = 90,fontsize = 7);\n",
    "plt.xlim([-1,len(res)])\n",
    "plt.ylabel('Intensity per area',fontsize = 14);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4fd9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the refined model and the atlas\n",
    "atlas,ontology,header = read_atlas()\n",
    "interact_stack_overlay_areas(refined_model,atlas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2789be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use this to check that the rotation makes sense\n",
    "tt = rotate_stack(stack.downsampled_stack[0],*res['angles']) # Performs the rotation\n",
    "interact_show_stack(tt)  # visualizes the stack"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
